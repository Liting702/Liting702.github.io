---
title: "2022周报"
date: 2022-04-18
categories:
  - Blog
tags:
  - report
---

以下为2022年周报：
# 本周主要工作（5.1至5.7）
- 实现代码，好难，我自己通过查找github和csdn上的代码，也请教了很多人，感觉这周什么都没做出来
— 接下来一周的工作：
   - 实现出代码




# 本周主要工作（4.24至4.30）
- 本周在准备期末考试内容
- 论文这一块有点落下了
— 接下来一周的工作：
   - 实现出代码



# 本周主要工作（4.17至4.23）
- 本周下载了比较多的有关不平衡数据的论文
- 查到和这篇文献思想一样的最早的论文是06年的，上周提到过的《一种改进的 AdaBoost 算法———AD AdaBoost》（来源：计算机学报）
- 着手动手实现论文第一个算法
— 接下来一周的工作：
   - 实现出代码
   

# 本周主要工作（4.10至4.16）
- 本周重新学了决策树的思想及代码编程
- 继续阅读《The improved Ada Boost algorithms for imbalanced dataclassiﬁcation》，（下面简称《1》）并和陈老师进行了讨论。讨论结果为对分类器权重公式中，比原始算法中多出来的部分，论文作者是怎么改的，为什么这样改，这样改在理论上起了什么作用。
- 查阅参考文献中的《一种改进的 AdaBoost 算法———AD AdaBoost》（来源：计算机学报）上，写出了改动部分的原始公式，其思想是阳样本分对的越高，权重越大。论文《1》的理论证明过程和这篇文章的理论证明过程高度相似。
- 论文《1》的改动部分有点像周五张凇铭在《深度学习和神经网络》中的惩罚项或激活函数类似。
— 接下来一周的工作：
   - 准备再多查阅一下文献看有没有人做过
   - 改成其他惩罚项后在理论上有没有用
   - 用代码实现一下论文《1》中的算法



# 本周主要工作（4.2至4.9）
- 仔细精读《The improved Ada Boost algorithms for imbalanced dataclassiﬁcation》
- 里面有些公式理解了比较久，有关理论的证明在附录里面，写的比较简略，
我自己把它全部推出来了（证明不多），这篇论文研究的是进行分类过程时，如果出现在数据集中
，阳性样本远远小于阴性样本时，数据出现类不平衡问题，比如100个西瓜中只有1个坏瓜，那我直接设置一个分类器把所有的西瓜都分类为好瓜，那么这个分类器的准确率就是百分之99了（例子举的比较夸张，意思是这么个意思），显然没有什么意义，
所以类不平衡问题还算机器学习中很关键的问题。
-准备分享的论文是《The improved Ada Boost algorithms for imbalanced dataclassiﬁcation》

