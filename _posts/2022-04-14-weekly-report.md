---
title: "2022周报"
date: 2022-04-18
categories:
  - Blog
tags:
  - report
---

以下为2022年周报：
#本周主要工作（5.8至5.14）：

- 关于代码问题：实现出了上周规划的代码，在单层决策树作为弱分类器的条件下，根据论文中的方法实现出代码，效果在某些数据集上不理想，应该是单层决策树的问题。单层决策树相当于一个树桩，比如整个数据集的特征维数有5维，单层决策树在这5维中选择一维最具有代表性的维度，这样其实是不合理的，相当于其他剩余4维被浪费了。如果是特征维数非常多的数据集，有必要减少特征维数，但是在我预计要用的数据集中，没有那么多的特征维数。所以在代码中不再使用单层决策树，改为调用sk learn中自带的决策树（已实现），还可以把调用sk learn中自带的决策树改为调用sk learn中自带的支持向量机（已实现）。

- 关于论文改进：根据陈老师提到的“扬长避短”的建议，就是把分错的样本的权重进一步加大，但是可能会出现过拟合的问题，去查找文献。文献暂时还没查到，但是根据一些文献和博客，发现adaboost是不容易过拟合的，因为Adaboost有很优秀的抵抗过拟合的特性。
-接下来一周的工作：
  -找到更合适的函数进行改进，以及继续查找相关文献 
# 本周主要工作（5.1至5.7）
- 实现代码，好难，我自己通过查找github和csdn上的代码，也请教了很多人，感觉这周什么都没做出来
— 接下来一周的工作：
   - 实现出代码




# 本周主要工作（4.24至4.30）
- 本周在准备期末考试内容
- 论文这一块有点落下了
— 接下来一周的工作：
   - 实现出代码



# 本周主要工作（4.17至4.23）
- 本周下载了比较多的有关不平衡数据的论文
- 查到和这篇文献思想一样的最早的论文是06年的，上周提到过的《一种改进的 AdaBoost 算法———AD AdaBoost》（来源：计算机学报）
- 着手动手实现论文第一个算法
— 接下来一周的工作：
   - 实现出代码
   

# 本周主要工作（4.10至4.16）
- 本周重新学了决策树的思想及代码编程
- 继续阅读《The improved Ada Boost algorithms for imbalanced dataclassiﬁcation》，（下面简称《1》）并和陈老师进行了讨论。讨论结果为对分类器权重公式中，比原始算法中多出来的部分，论文作者是怎么改的，为什么这样改，这样改在理论上起了什么作用。
- 查阅参考文献中的《一种改进的 AdaBoost 算法———AD AdaBoost》（来源：计算机学报）上，写出了改动部分的原始公式，其思想是阳样本分对的越高，权重越大。论文《1》的理论证明过程和这篇文章的理论证明过程高度相似。
- 论文《1》的改动部分有点像周五张凇铭在《深度学习和神经网络》中的惩罚项或激活函数类似。
— 接下来一周的工作：
   - 准备再多查阅一下文献看有没有人做过
   - 改成其他惩罚项后在理论上有没有用
   - 用代码实现一下论文《1》中的算法



# 本周主要工作（4.2至4.9）
- 仔细精读《The improved Ada Boost algorithms for imbalanced dataclassiﬁcation》
- 里面有些公式理解了比较久，有关理论的证明在附录里面，写的比较简略，
我自己把它全部推出来了（证明不多），这篇论文研究的是进行分类过程时，如果出现在数据集中
，阳性样本远远小于阴性样本时，数据出现类不平衡问题，比如100个西瓜中只有1个坏瓜，那我直接设置一个分类器把所有的西瓜都分类为好瓜，那么这个分类器的准确率就是百分之99了（例子举的比较夸张，意思是这么个意思），显然没有什么意义，
所以类不平衡问题还算机器学习中很关键的问题。
-准备分享的论文是《The improved Ada Boost algorithms for imbalanced dataclassiﬁcation》

